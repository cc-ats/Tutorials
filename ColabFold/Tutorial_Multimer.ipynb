{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cc-ats/Tutorials/blob/main/ColabFoldTutorial_Multimer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# @title **Install Python Packages** { run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "from sys import version_info\n",
        "PYTHON_VERSION = f\"{version_info.major}.{version_info.minor}\"\n",
        "\n",
        "if not os.path.isfile(\"COLABFOLD_READY\"):\n",
        "  print(\"installing colabfold...\")\n",
        "  os.system(\"pip install -q --no-warn-conflicts 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
        "  os.system(\"pip install --upgrade dm-haiku\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\")\n",
        "  # patch for jax > 0.3.25\n",
        "  os.system(\"sed -i 's/weights = jax.nn.softmax(logits)/logits=jnp.clip(logits,-1e8,1e8);weights=jax.nn.softmax(logits)/g' alphafold/model/modules.py\")\n",
        "  os.system(\"touch COLABFOLD_READY\")\n",
        "\n",
        "\n",
        "if not os.path.isfile(\"CONDA_READY\"):\n",
        "  print(\"installing conda...\")\n",
        "  os.system(\"wget -qnc https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\")\n",
        "  os.system(\"bash Miniforge3-Linux-x86_64.sh -bfp /usr/local\")\n",
        "  os.system(\"conda config --set auto_update_conda false\")\n",
        "  os.system(\"touch CONDA_READY\")\n",
        "\n",
        "\n",
        "if not os.path.isfile(\"CONDA_READY\"):\n",
        "  print(\"installing conda...\")\n",
        "  os.system(\"wget -qnc https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh\")\n",
        "  os.system(\"bash Mambaforge-Linux-x86_64.sh -bfp /usr/local\")\n",
        "  os.system(\"mamba config --set auto_update_conda false\")\n",
        "  os.system(\"touch CONDA_READY\")\n",
        "\n",
        "\n",
        "if not os.path.isfile(\"HH_READY\") and not os.path.isfile(\"AMBER_READY\"):\n",
        "  print(\"installing hhsuite and amber...\")\n",
        "  os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 openmm=7.7.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "  os.system(\"touch HH_READY\")\n",
        "  os.system(\"touch AMBER_READY\")\n",
        "else:\n",
        "  if not os.path.isfile(\"HH_READY\"):\n",
        "    print(\"installing hhsuite...\")\n",
        "    os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python='{PYTHON_VERSION}'\")\n",
        "    os.system(\"touch HH_READY\")\n",
        "  if not os.path.isfile(\"AMBER_READY\"):\n",
        "    print(\"installing amber...\")\n",
        "    os.system(f\"mamba install -y -c conda-forge openmm=7.7.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "    os.system(\"touch AMBER_READY\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CX768sUrS7lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTVzPTKjTjXX"
      },
      "source": [
        "# 1. **ColabFold Tutorial:** Predicting Protein-Protein Complexes of TA Systems\n",
        "\n",
        "Like the monomer example, we will use the default options set by Steinegger *et al.* which excludes Amber minimization and structure templates.\n",
        "\n",
        "Predicting the structure of protein complexes can be investigated using the AlphaFold oligomers\n",
        "\n",
        "There are subtle differences when running the AF-Multimer externsion:\n",
        "\n",
        "- Model confidence metric is iPTM\n",
        "  - Interference predicted template modelling score\n",
        "- Better for homomeric interfaces than for heteromeric interfaces (high conservation)\n",
        "- COM between chains are added to the loss function\n",
        "\n",
        "This example focuses on a toxin-antitoxin (TA) protein system, prevalent in bacterial systems. Toxins, or over-expressed proteins, become accumulated in the cell causing disturbing other cellular processes. Yet, their natural role aids in infections and apoptosis. Antitoxin, protein or RNA, can neutralize the toxin by forming stable complexes. How does the protein-protein interactions  maintianing a balance between the toxin and antitoxin.  \n",
        "\n",
        "We will predict the TA complex in *Vibrio cholerae*, specifically, VCParD1/2 (antitoxin) and VcParE (toxin)1/2.\n",
        "\n",
        "**a. Background**\n",
        "  - TA systems are essential in maintaining cellular homeostasis\n",
        "  - Low sequence similariy to maintain specificity towards cognate receptor\n",
        "  - ParDE was the first TA system to be identified as a stabilizing element upon plasmisd loss\n",
        "  - Potential in biotechnological applications\n",
        "\n",
        "**b. ParE attenuates Toxicity Protecting Cells**\n",
        "  - ParE can inhibit DNA gyrase supercoiling\n",
        "  - Protects from anti-gyrase antibiotitcs\n",
        "  - At the same time ParD is degraded\n",
        "  - C-terminal domain is key to formation of PaParDE complexes\n",
        "  \n",
        "The C-terminal residues of ParD was found to be crucial in formation and stabilizatino of toxin-antitoxin complexes. This resulted in protection from proteases and attenuates toxicitiy from antibiotics in bacterial systems.\n",
        "\n",
        "Interestingly, structure-based studies have resolved several oligomeric TA complexes. Despite low sequence similarity, their structure is highly conserved. Let's investivate VcParDE and later compare it with PaParDE.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOblAo-xetgx"
      },
      "outputs": [],
      "source": [
        "#@title # **2. Notebook Setup** { display-mode: \"form\" }\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "\n",
        "from sys import version_info\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "\n",
        "def add_hash(x,y):\n",
        "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ##a. Protein Sequence for Structure Prediction\n",
        "#@markdown For bax (human), the amino acid sequence was obtained from\n",
        "#@markdown UniProt ([Q07812](https://www.uniprot.org/uniprotkb/Q07812/entry))\n",
        "query_sequence = 'MHTLTANDAKRNFGELLLSAQREPVIISKNSKNTVVVMSIKDFEELEAMKLDYLKHCFESAQKDLDSGKTVDGATFLNTL:MQNKQYKLSQLAQEHLLKIKHYTIENFAEAQWQKYKSTLLSGFQTLADNPGLGKSCEDIYQNGFYFPVGKHMAYYTKEANFILIVAVLGQSQLPQKHLKQSRFVS:MAKNTSITLGEHFDGFITSQIQSGRYGSASEVIRSALRLLENQETKLQSLRQLLIEGEQSGDADYDLDSFINELDSENI:MKPFNLTVAAKADLRDIALFTQRRWGKEQRNVYLKQFDDSFWLLAENPDIGKSCDEIREGYRKFPQGSHVIFYQQTGSQQIRVIRILHKSMDVNPIFGA ' #@param {type:\"string\"}\n",
        "#@markdown **Note:** For modeling complexes, use `:` to specify inter-protein chainbreaks\n",
        "#@markdown (supports homo- and hetro-oligomers).\n",
        "#@markdown For example, **PI...SK:PI...SK** for a homodimer.\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ## b. Job Name (also name of saving directory)\n",
        "jobname = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown  ## c. Number of predicted models to relax using Amber\n",
        "num_relax = 5 #@param [0, 1, 5] {type:\"raw\"}\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ## **d. Option for Structure Template**\n",
        "#@markdown  Search for PDB structure (xyz-coordinates)\n",
        "template_mode = \"none\" #@param [\"none\", \"pdb100\",\"custom\"]\n",
        "#@markdown `none` = no template information is used. \\\n",
        "#@markdown `pdb100` = detect templates in pdb100 (see [notes](#pdb100)). \\\n",
        "#@markdown `custom` - upload and search own templates (PDB or mmCIF format, see [notes](#custom_templates))\n",
        "\n",
        "use_amber = num_relax > 0\n",
        "\n",
        "query_sequence = \"\".join(query_sequence.split()) # remove whitespaces\n",
        "\n",
        "basejobname = \"\".join(jobname.split())\n",
        "basejobname = re.sub(r'\\W+', '', basejobname)\n",
        "jobname = add_hash(basejobname, query_sequence)\n",
        "\n",
        "# check if directory with jobname exists\n",
        "def check(folder):\n",
        "  if os.path.exists(folder):\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "if not check(jobname):\n",
        "  n = 0\n",
        "  while not check(f\"{jobname}_{n}\"): n += 1\n",
        "  jobname = f\"{jobname}_{n}\"\n",
        "\n",
        "# make directory to save results\n",
        "os.makedirs(jobname, exist_ok=True)\n",
        "\n",
        "# save queries\n",
        "queries_path = os.path.join(jobname, f\"{jobname}.csv\")\n",
        "with open(queries_path, \"w\") as text_file:\n",
        "  text_file.write(f\"id,sequence\\n{jobname},{query_sequence}\")\n",
        "\n",
        "if template_mode == \"pdb100\":\n",
        "  use_templates = True\n",
        "  custom_template_path = None\n",
        "elif template_mode == \"custom\":\n",
        "  custom_template_path = os.path.join(jobname,f\"template\")\n",
        "  os.makedirs(custom_template_path, exist_ok=True)\n",
        "  uploaded = files.upload()\n",
        "  use_templates = True\n",
        "  for fn in uploaded.keys():\n",
        "    os.rename(fn,os.path.join(custom_template_path,fn))\n",
        "else:\n",
        "  custom_template_path = None\n",
        "  use_templates = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2_sh2uAonJH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title # **3. Multiple Sequence Alignment (MSA)**\n",
        "\n",
        "#@markdown ## a. MSA options\n",
        "msa_mode = \"mmseqs2_uniref_env\" #@param [\"mmseqs2_uniref_env\", \"mmseqs2_uniref\",\"single_sequence\",\"custom\"]\n",
        "#@markdown - pairing mode\n",
        "#@markdown - single sequence\n",
        "#@markdown - custom MSA upload\n",
        "\n",
        "#@markdown \\\n",
        "pair_mode = \"unpaired_paired\" #@param [\"unpaired_paired\",\"unpaired\",\"paired\"] {type:\"string\"}\n",
        "#@markdown - \"unpaired_paired\" - pair sequences from same species + unpaired MSA\n",
        "#@markdown - \"unpaired\" - seperate MSA for each chain\n",
        "#@markdown - \"paired\" - only use paired sequences\n",
        "\n",
        "# decide which a3m to use\n",
        "if \"mmseqs2\" in msa_mode:\n",
        "  a3m_file = os.path.join(jobname,f\"{jobname}.a3m\")\n",
        "\n",
        "elif msa_mode == \"custom\":\n",
        "  a3m_file = os.path.join(jobname,f\"{jobname}.custom.a3m\")\n",
        "  if not os.path.isfile(a3m_file):\n",
        "    custom_msa_dict = files.upload()\n",
        "    custom_msa = list(custom_msa_dict.keys())[0]\n",
        "    header = 0\n",
        "    import fileinput\n",
        "    for line in fileinput.FileInput(custom_msa,inplace=1):\n",
        "      if line.startswith(\">\"):\n",
        "         header = header + 1\n",
        "      if not line.rstrip():\n",
        "        continue\n",
        "      if line.startswith(\">\") == False and header == 1:\n",
        "         query_sequence = line.rstrip()\n",
        "      print(line, end='')\n",
        "\n",
        "    os.rename(custom_msa, a3m_file)\n",
        "    queries_path=a3m_file\n",
        "    print(f\"moving {custom_msa} to {a3m_file}\")\n",
        "\n",
        "else:\n",
        "  a3m_file = os.path.join(jobname,f\"{jobname}.single_sequence.a3m\")\n",
        "  with open(a3m_file, \"w\") as text_file:\n",
        "    text_file.write(\">1\\n%s\" % query_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADDuaolKmjGW"
      },
      "outputs": [],
      "source": [
        "# @title # **4. Advanced Settings** { run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "#@markdown ## a. ML Model\n",
        "model_type = \"auto\" #@param [\"auto\", \"alphafold2_ptm\", \"alphafold2_multimer_v1\", \"alphafold2_multimer_v2\", \"alphafold2_multimer_v3\"]\n",
        "#@markdown **Note:** If `auto` selected, will use `alphafold2_ptm` for monomer prediction\n",
        "#@markdown and `alphafold2_multimer_v3` for complex prediction.\n",
        "#@markdown Any of the `mode_types` can be used (regardless if input is monomer or complex).\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ## b. Re-Train with Predicted Structures\n",
        "num_recycles = \"0\" #@param [\"auto\", \"0\", \"1\", \"3\", \"6\", \"12\", \"24\", \"48\"]\n",
        "#@markdown **Note:**\n",
        "#@markdown - If `auto` selected, will use `num_recycles=20`,\n",
        "#@markdown - If `model_type=alphafold2_multimer_v3`, else `num_recycles=3`\n",
        "\n",
        "#@markdown \\\n",
        "recycle_early_stop_tolerance = \"auto\" #@param [\"auto\", \"0.0\", \"0.5\", \"1.0\"]\n",
        "#@markdown - if `auto` selected, will use `tol=0.5`\n",
        "#@markdown - If `model_type=alphafold2_multimer_v3`,  else `tol=0.0`.\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ## c. Amber Relaxation\n",
        "relax_max_iterations = 200 #@param [0, 200, 2000] {type:\"raw\"}\n",
        "#@markdown - max amber relax iterations\n",
        "#@markdown -  `0` = unlimited (AlphaFold2 default, can take very long)\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ## d. MSA Pairing\n",
        "pairing_strategy = \"greedy\" #@param [\"greedy\", \"complete\"] {type:\"string\"}\n",
        "#@markdown - `greedy` = pair any taxonomically matching subsets,\n",
        "#@markdown - `complete` = all sequences have to match in one line.\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ## e. Sample settings\n",
        "#@markdown -  enable dropouts and increase number of seeds to sample predictions from uncertainty of the model.\n",
        "#@markdown -  decrease `max_msa` to increase uncertainity\n",
        "max_msa = \"auto\" #@param [\"auto\", \"512:1024\", \"256:512\", \"64:128\", \"32:64\", \"16:32\"]\n",
        "num_seeds = 1 #@param [1,2,4,8,16] {type:\"raw\"}\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "\n",
        "num_recycles = None if num_recycles == \"auto\" else int(num_recycles)\n",
        "recycle_early_stop_tolerance = None if recycle_early_stop_tolerance == \"auto\" else float(recycle_early_stop_tolerance)\n",
        "if max_msa == \"auto\": max_msa = None\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown # **5. Save settings**\n",
        "#@markdown This will ask for your credentials, to save the outputs.\n",
        "save_all = False #@param {type:\"boolean\"}\n",
        "save_recycles = False #@param {type:\"boolean\"}\n",
        "save_to_google_drive = False #@param {type:\"boolean\"}\n",
        "#@markdown -  if the save_to_google_drive option was selected, the result zip will be uploaded to your Google Drive\n",
        "dpi = 200 #@param {type:\"integer\"}\n",
        "#@markdown - set dpi for image resolution\n",
        "\n",
        "if save_to_google_drive:\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print(\"You are logged into Google Drive and are good to go!\")\n",
        "\n",
        "#@markdown Don't forget to hit `Runtime` -> `Run all` after updating the form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbaIO9pWjaN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b0f5d314-ac48-46bb-906c-88ee9506ad5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-08 03:34:55,968 alphafold2_multimer_v3_model_2_seed_000 recycle=18 pLDDT=85.8 pTM=0.479 ipTM=0.372 tol=0.629\n",
            "2023-12-08 03:35:09,602 alphafold2_multimer_v3_model_2_seed_000 recycle=19 pLDDT=85.5 pTM=0.478 ipTM=0.374 tol=1.08\n"
          ]
        }
      ],
      "source": [
        "#@title # **6. Run Prediction** { display-mode: \"form\" }\n",
        "\n",
        "display_images = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from Bio import BiopythonDeprecationWarning\n",
        "warnings.simplefilter(action='ignore', category=BiopythonDeprecationWarning)\n",
        "from pathlib import Path\n",
        "from colabfold.download import download_alphafold_params, default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "from colabfold.batch import get_queries, run, set_model_type\n",
        "from colabfold.plot import plot_msa_v2\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "try:\n",
        "  K80_chk = os.popen('nvidia-smi | grep \"Tesla K80\" | wc -l').read()\n",
        "except:\n",
        "  K80_chk = \"0\"\n",
        "  pass\n",
        "if \"1\" in K80_chk:\n",
        "  print(\"WARNING: found GPU Tesla K80: limited to total length < 1000\")\n",
        "  if \"TF_FORCE_UNIFIED_MEMORY\" in os.environ:\n",
        "    del os.environ[\"TF_FORCE_UNIFIED_MEMORY\"]\n",
        "  if \"XLA_PYTHON_CLIENT_MEM_FRACTION\" in os.environ:\n",
        "    del os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]\n",
        "\n",
        "from colabfold.colabfold import plot_protein\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For some reason we need that to get pdbfixer to import\n",
        "if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "def input_features_callback(input_features):\n",
        "  if display_images:\n",
        "    plot_msa_v2(input_features)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def prediction_callback(protein_obj, length,\n",
        "                        prediction_result, input_features, mode):\n",
        "  model_name, relaxed = mode\n",
        "  if not relaxed:\n",
        "    if display_images:\n",
        "      fig = plot_protein(protein_obj, Ls=length, dpi=150)\n",
        "      plt.show()\n",
        "      plt.close()\n",
        "\n",
        "result_dir = jobname\n",
        "log_filename = os.path.join(jobname,\"log.txt\")\n",
        "setup_logging(Path(log_filename))\n",
        "\n",
        "queries, is_complex = get_queries(queries_path)\n",
        "model_type = set_model_type(is_complex, model_type)\n",
        "\n",
        "if \"multimer\" in model_type and max_msa is not None:\n",
        "  use_cluster_profile = False\n",
        "else:\n",
        "  use_cluster_profile = True\n",
        "\n",
        "download_alphafold_params(model_type, Path(\".\"))\n",
        "results = run(\n",
        "    queries=queries,\n",
        "    result_dir=result_dir,\n",
        "    use_templates=use_templates,\n",
        "    custom_template_path=custom_template_path,\n",
        "    num_relax=num_relax,\n",
        "    msa_mode=msa_mode,\n",
        "    model_type=model_type,\n",
        "    num_models=5,\n",
        "    num_recycles=num_recycles,\n",
        "    relax_max_iterations=relax_max_iterations,\n",
        "    recycle_early_stop_tolerance=recycle_early_stop_tolerance,\n",
        "    num_seeds=num_seeds,\n",
        "    use_dropout=use_dropout,\n",
        "    model_order=[1,2,3,4,5],\n",
        "    is_complex=is_complex,\n",
        "    data_dir=Path(\".\"),\n",
        "    keep_existing_results=False,\n",
        "    rank_by=\"auto\",\n",
        "    pair_mode=pair_mode,\n",
        "    pairing_strategy=pairing_strategy,\n",
        "    stop_at_score=float(100),\n",
        "    prediction_callback=prediction_callback,\n",
        "    dpi=dpi,\n",
        "    zip_results=False,\n",
        "    save_all=save_all,\n",
        "    max_msa=max_msa,\n",
        "    use_cluster_profile=use_cluster_profile,\n",
        "    input_features_callback=input_features_callback,\n",
        "    save_recycles=save_recycles,\n",
        "    user_agent=\"colabfold/google-colab-main\",\n",
        ")\n",
        "results_zip = f\"{jobname}.result.zip\"\n",
        "os.system(f\"zip -r {results_zip} {jobname}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK7X9T44pWb7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title # **7. Visualize 3D Structure of ColabFold Prediction** { run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "#@markdown Rank number/score for the **monomer model is the average pLDDT**,\n",
        "#@markdown where a ranking of 1 correlates better local structure confidence.\n",
        "#@markdown An acceptable model prediction should average $\\ge 85$.\n",
        "#@markdown The number of ranked models was set in step `6. Run Prediction` (step 6, line 75.).\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown Here, you can change the value for `rank_num` to visualize the 5 predictions.\n",
        "\n",
        "import py3Dmol\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from colabfold.colabfold import plot_plddt_legend\n",
        "from colabfold.colabfold import pymol_color_list, alphabet_list\n",
        "\n",
        "rank_num = 1 #@param [\"1\", \"2\", \"3\", \"4\", \"5\"] {type:\"raw\"}\n",
        "color = \"rainbow\" #@param [\"chain\", \"lDDT\", \"rainbow\"]\n",
        "show_sidechains = False #@param {type:\"boolean\"}\n",
        "show_mainchains = False #@param {type:\"boolean\"}\n",
        "\n",
        "tag = results[\"rank\"][0][rank_num - 1]\n",
        "jobname_prefix = \".custom\" if msa_mode == \"custom\" else \"\"\n",
        "pdb_filename = f\"{jobname}/{jobname}{jobname_prefix}_unrelaxed_{tag}.pdb\"\n",
        "pdb_file = glob.glob(pdb_filename)\n",
        "\n",
        "def show_pdb(rank_num=1, show_sidechains=False, show_mainchains=False, color=\"lDDT\"):\n",
        "  model_name = f\"rank_{rank_num}\"\n",
        "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js',)\n",
        "  view.addModel(open(pdb_file[0],'r').read(),'pdb')\n",
        "\n",
        "\n",
        "  if color == \"lDDT\":\n",
        "    view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':50,'max':90}}})\n",
        "  elif color == \"rainbow\":\n",
        "    view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "  elif color == \"chain\":\n",
        "    chains = len(queries[0][1]) + 1 if is_complex else 1\n",
        "    for n,chain,color in zip(range(chains),alphabet_list,pymol_color_list):\n",
        "       view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
        "\n",
        "  if show_sidechains:\n",
        "    BB = ['C','O','N']\n",
        "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
        "                        {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "  if show_mainchains:\n",
        "    BB = ['C','O','N','CA']\n",
        "    view.addStyle({'atom':BB},{'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}}, viewer=(0,0))\n",
        "\n",
        "  view.zoomTo()\n",
        "  return view\n",
        "\n",
        "print('Prediction: Rank %d' % rank_num)\n",
        "show_pdb(rank_num, show_sidechains, show_mainchains, color).show()\n",
        "if color == \"lDDT\":\n",
        "  plot_plddt_legend().show()\n",
        "\n",
        "\n",
        "#@markdown \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33g5IIegij5R"
      },
      "outputs": [],
      "source": [
        "#@title **8. Package and Download**\n",
        "\n",
        "#@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "\n",
        "if msa_mode == \"custom\":\n",
        "  print(\"Don't forget to cite your custom MSA generation method.\")\n",
        "\n",
        "files.download(f\"{jobname}.result.zip\")\n",
        "\n",
        "if save_to_google_drive == True and drive:\n",
        "  uploaded = drive.CreateFile({'title': f\"{jobname}.result.zip\"})\n",
        "  uploaded.SetContentFile(f\"{jobname}.result.zip\")\n",
        "  uploaded.Upload()\n",
        "  print(f\"Uploaded {jobname}.result.zip to Google Drive with ID {uploaded.get('id')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_yNIT-iBd65"
      },
      "source": [
        "Colab notebooks are adapted from:\n",
        "  - [AlphaFold2 Colab](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb)\n",
        "  - [Mirdita M, Schütze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
        "*Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1)\n",
        "\n",
        "*From the original notebook:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGUBLzB3C6WN"
      },
      "source": [
        "> <img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"200\" align=\"right\" style=\"height:240px\">\n",
        ">\n",
        "> ## ColabFold v1.5.3: AlphaFold2 using MMseqs2\n",
        ">\n",
        "> Easy to use protein structure and complex prediction using [AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2) and [Alphafold2-multimer](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1). Sequence alignments/templates are generated through [MMseqs2](mmseqs.com) and [HHsearch](https://github.com/soedinglab/hh-suite). For more details, see <a href=\"#Instructions\">bottom</a> of the notebook, checkout the [ColabFold GitHub](https://github.com/sokrypton/ColabFold) and read our manuscript.\n",
        ">\n",
        "> Old versions: [v1.4](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.4.0/AlphaFold2.ipynb), [v1.5.1](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.1/AlphaFold2.ipynb), [v1.5.2](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.2/AlphaFold2.ipynb)\n",
        ">\n",
        "> [Mirdita M, Schütze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
        "> *Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1)\n",
        ">\n",
        "> -----------\n",
        ">\n",
        "> ### News\n",
        "> - <b><font color='green'>2023/07/31: The ColabFold MSA server is back to normal. It was using older DB (UniRef30 2202/PDB70 220313) from 27th ~8:30 AM CEST to 31st ~11:10 AM CEST.</font></b>\n",
        "> - <b><font color='green'>2023/06/12: New databases! UniRef30 updated to 2023_02 and PDB to 230517. We now use PDB100 instead of PDB70 (see [notes](#pdb100)).</font></b>\n",
        "> - <b><font color='green'>2023/06/12: We introduced a new default pairing strategy: Previously, for multimer predictions with more than 2 chains, we only pair if all sequences taxonomically match (\"complete\" pairing). The new default \"greedy\" strategy pairs any taxonomically matching subsets.</font></b>\n",
        ">\n",
        "># Instructions <a name=\"Instructions\"></a>\n",
        ">\n",
        "> **Quick start**\n",
        "> 1. Paste your protein sequence(s) in the input field.\n",
        "> 2. Press \"Runtime\" -> \"Run all\".\n",
        "> 3. The pipeline consists of 5 steps. The currently running step is indicated by a circle with a stop sign next to it.\n",
        ">\n",
        "> **Result zip file contents**\n",
        ">\n",
        "> 1. PDB formatted structures sorted by avg. pLDDT and complexes are sorted by pTMscore. (unrelaxed and relaxed if `use_amber` is enabled).\n",
        "> 2. Plots of the model quality.\n",
        "> 3. Plots of the MSA coverage.\n",
        "> 4. Parameter log file.\n",
        "> 5. A3M formatted input MSA.\n",
        "> 6. A `predicted_aligned_error_v1.json` using [AlphaFold-DB's format](https://alphafold.ebi.ac.uk/faq#faq-7) and a `scores.json` for each model which contains  an array (list of lists) for PAE, a list with the average pLDDT and the pTMscore.\n",
        "> 7. BibTeX file with citations for all used tools and databases.\n",
        ">\n",
        "> At the end of the job a download modal box will pop up with a `jobname.result.zip` file. Additionally, if the `save_to_google_drive` option was selected, the `jobname.result.zip` will be uploaded to your Google Drive.\n",
        ">  \n",
        ">\n",
        "> **License**\n",
        "> githubusercontent.com/sokrypton/ColabFold/main/LICENSE). Additionally, this > notebook uses the AlphaFold2 source code and its parameters licensed under [Apache 2.0](https://raw.githubusercontent.com/deepmind/alphafold/main/LICENSE) > and [CC BY 4.0](https://creativecommons.org/licenses/by-sa/4.0/) respectively. Read more about the AlphaFold license [here](https://github.com/deepmind/> alphafold).\n",
        ">\n",
        "> **Acknowledgments**\n",
        "> - We thank the AlphaFold team for developing an excellent model and open > sourcing the software.\n",
        ">\n",
        "> - [KOBIC](https://kobic.re.kr) and [Söding Lab](https://www.mpinat.mpg.de/soeding) for providing the computational resources for the MMseqs2 MSA server.\n",
        ">\n",
        "> - Richard Evans for helping to benchmark the ColabFold's Alphafold-multimer support.\n",
        ">\n",
        "> - [David Koes](https://github.com/dkoes) for his awesome [py3Dmol](https://3dmol.csb.pitt.edu/) plugin, without whom these notebooks would be quite boring!\n",
        ">\n",
        "> - Do-Yoon Kim for creating the ColabFold logo.\n",
        ">\n",
        "> - A colab by Sergey Ovchinnikov ([@sokrypton](https://twitter.com/sokrypton)), Milot Mirdita ([@milot_mirdita](https://twitter.com/milot_mirdita)) and Martin Steinegger ([@thesteinegger](https://twitter.com/thesteinegger)).\n",
        ">\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "cell_execution_strategy": "setup",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}